---
title: "Final_project"
format: html
editor: visual
echo: false
author: 'Andrew Castillo, Ania Grudzien, Kayla McComb'
bibliography: ../data/references.bib
---

## Final Project

# Data

Our final project will use a large-scale cross-sectional dataset with psychological variables. This data will be simulated to emulate the real dataset (sourced from www.sapa-project.org, my advisor’s data collection platform). The dimensions will be 105 columns and ~10,000 rows, where each row represents a participant’s responses to a survey of 100 items and the content of the item, along with the respondent’s age, gender identity, race, and geographic location. Values will be numerical, ranging from 1 to 6 for the 100 items. The demographic variables will be strings, except for age, which will also be in numeric format. Four latent factors will be built into the data in order to make a factor analysis viable; the items are based on a scale measuring maladaptive imagination, and the factors are 1) Anxiety 2) Hopelessness 3) Resentment and 4) Shame.

# Preparatory Work

To prepare our data for analysis, we will need to simulate it. This will be achieved using rnorm() and round(). The four factors will be simulated separately in “blocks” of 25 items each and merged together. These blocks will have different, randomly selected means and standard deviations in order to allow the factor analysis to locate the desired clusters of items from each of the factors. A spattering of NAs will also be introduced using something like this: sample(1:n, 0.15*nrow(data)*ncol(data), replace = T) paired with a for loop. This will introduce some amount of missingness (in this case, 15%) to make the data more realistic and add a bit of intrigue and decision making around handling the missing data. After this, the data will be ready for analysis including imputation, removal of missing data, partitioning into holdouts, and more. In this stage, we will use mutate() and other tidyverse() functions per the project requirements.

# Meeting Project Requirements

This dataset is “real world” in the psychometrics sub-discipline of psychology, which is concerned with measurement of psychological traits. The fact that it is simulated means it will be able to be posted publicly on GitHub. We will be able to produce a miniature manuscript detailing the scale development process, which may provide our group with a reference as we continue to develop best practices for reproducible science. This data will provide us with a wealth of opportunities, such as but not limited to, factor analysis, imputation (or not), cross-validation on holdout data, and data visualizations charting factor structures and item loadings. 

```{r}
suppressMessages(suppressWarnings(library(rio)))
suppressMessages(suppressWarnings(library(here)))
suppressMessages(suppressWarnings(library(psych)))
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(tidyr)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(corrplot)))
suppressMessages(suppressWarnings(library(glmnet)))
suppressMessages(suppressWarnings(library(tidyverse)))
```

## Simulating the data

Data is simulated using a random sampling procedure. Four latent factors consisting of items rated 1 - 6 are produced using the sample() function and stored into a dataframe.

```{r}
set.seed(7)

n_respondents <- 10000

simulated_data <- data.frame(matrix(ncol = 100, nrow = n_respondents))
colnames(simulated_data) <- paste0("item_", 1:100)

# Loop to simulate factor1 25 times
for (i in 1:25) {
    # Simulate factor1
    simulated_factor1 <- sample(1:5, n_respondents, replace = TRUE, prob = c(0.1, 0.2, 0.4, 0.2, 0.1)) #Mean closer to 3
    simulated_data[,i] <- simulated_factor1
}

for (i in 1:25) {
    # Simulate factor2
    simulated_factor2 <- sample(1:5, n_respondents, replace = TRUE, prob = c(0.2, 0.3, 0.3, 0.1, 0.1)) #Mean closer to 2

simulated_data[,i+25] <- simulated_factor2
}

for (i in 1:25) {
    # Simulate factor3
    simulated_factor3 <- sample(1:5, n_respondents, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.3, 0.3)) #Mean closer to 4
    simulated_data[,i+50] <- simulated_factor3
}

for (i in 1:25) {
    # Simulate factor4
    simulated_factor4 <- sample(1:5, n_respondents, replace = TRUE, prob = c(0.25, 0.25, 0.2, 0.15, 0.15)) #Mean closer to 2.5
    simulated_data[,i+75] <- simulated_factor4
}

gender <- sample(c("F", "M"), n_respondents, replace = TRUE, prob = c(0.66, 0.34)) #Simulating gender. 66% F/34% M as per the original sample.

ages <- pmax(pmin(round(rnorm(n_respondents, mean = 30, sd = 14)), 99), 18) #Simulating skewed distribution with a mean around 30, sd of around 14 as per the original sample.

race_categories <- c("White", "Black", "Asian", "Hispanic", "Other") #Simulating race similar to the original data
race <- sample(race_categories, n_respondents, replace = TRUE, prob = c(0.7, 0.05, 0.1, 0.1, 0.05))

countries <- c("USA", "Canada", "UK", "Germany", "Australia", "India", "China", "Brazil", "South Africa", "Japan") #Simulating location using a subset of countries (using all 200 is too taxing for this project)
geographic_location <- sample(countries, n_respondents, replace = TRUE, prob = c(0.3, 0.1, 0.1, 0.05, 0.05, 0.1, 0.1, 0.1, 0.05, 0.05))

participant_id <- sprintf("%05d", 1:n_respondents) #Giving each row a unique identifier

#Making it harder on ourselves by including missing data (the real data has a lot of missingness)
num_missing <- round(0.15 * n_respondents)

#Function to introduce missing data into a column
introduce_missing <- function(column) {
    #Randomly select indices to be set as NA
    missing_indices <- sample(1:n_respondents, num_missing, replace = FALSE)
    column[missing_indices] <- NA
    return(column)
}

#Here, we introduce 15% missingness into the data
for(i in 1:100){
  simulated_data[,i] <- introduce_missing(simulated_data[,i])
}

scale_data <- data.frame(participant_id, ages, factor(gender), factor(race), factor(geographic_location), simulated_data) #Consolidating everything into one set.

#NOTE: In the scale data, item_1 through item_25 correspond to factor 1, and so on up to factor 4.

colnames(scale_data)[1:5] <- c('participant_id', 'age', 'gender', 'race', 'country') #Cleaning up the names

write.csv(scale_data, here(file_path <- here("data", "scale_data.csv"))) #Saving it to the data folder

```

## Properties of the data

Below are basic descriptives of the data, including pairwise administrations, means, standard deviations, and the like.

```{r}
#Descriptives of the 100 items
descScaleItems <- psych::describe(scale_data[,6:105])

#Administrations of each
administrations <- describe(descScaleItems$n)

#Pairwise complete administrations
pwiseAdminsScaleItems <- pairwiseCount(scale_data[,6:105], diagonal = TRUE)
pwiseAdminsScaleItemsVec <- as.vector(pwiseAdminsScaleItems[lower.tri(pwiseAdminsScaleItems)])
pwiseAdminsScaleItemsVecDescribe <- psych::describe(pwiseAdminsScaleItemsVec)
pwiseAdminsScaleItemsVecDescribe
n_obs <- pwiseAdminsScaleItemsVecDescribe$mean #Mean number of pairwise-complete administrations of all items


```

## Tidying the data

Cleaning the data involves the handling of missing values. 15% of the data is missing and there are no complete rows. In order to address this missingness, imptuation is used  with the makeX() function from the glmnet() package.

```{r}
#Handling NAs by replacing with mean of column 

for (i in 7:ncol(scale_data)) {
  scale_data[[i]][is.na(scale_data[[i]])] <- mean(scale_data[[i]], na.rm = TRUE)
}
imp_sim <- makeX(simulated_data, na.impute = TRUE, sparse = FALSE)


#creates version of data where each row is an individual score 

scale_data_long <- pivot_longer(
  data = scale_data,
  cols = 6:105,
  names_to = "item",
  values_to = "score"
)

#creates version of data where each participant has 4 rows (one for each factor)

scale_data_wide <- scale_data_long %>% 
  mutate(item = parse_number(item)) %>% 
  mutate(factor = case_when(
    item <= 25 ~ 1,
    item > 25 & item <= 50 ~ 2,
    item > 50 & item <= 75 ~ 3,
    item > 75 ~ 4)) %>% 
  pivot_wider(
    names_from = item,
    values_from = score
  )

#creates separate dataframes for each factor 

factor_1 <- scale_data %>% 
  select(1:30)

factor_2 <- scale_data %>% 
  select(1:5, 31:55)

factor_3 <- scale_data %>% 
  select(1:5, 56:80)

factor_4 <- scale_data %>% 
  select(1:5, 81:105)

```

## Visualizing the data

The data is visualized in mutliple ways, including a correlation table, heatmap, and other plots.

```{r}

#doing a correlation matrix of all the items

matrix <- cor(imp_sim, use="pairwise") 

heatmap(matrix, Rowv = NA, Colv = NA)

#making a correlation plot 
corrplot(corr= matrix, method = "square")


#Correlation matrix for each factor starting with factor 1

matrix1 <-cor(imp_sim[,1:25], use="pairwise") 
head(unlist(matrix)[,1:5], 10)
corrplot(corr= matrix1, method = "square")

#Correlation matrix for factor 2
matrix2 <-cor(imp_sim[,26:50], use="pairwise") 
head(unlist(matrix)[,1:5], 10)
corrplot(corr= matrix2, method = "square")

#Correlation matrix for factor 3
matrix3 <-cor(imp_sim[,51:75], use="pairwise") 
head(unlist(matrix)[,1:5], 10)
corrplot(corr= matrix3, method = "square")

#Correlation matrix for factor 4
matrix4 <-cor(imp_sim[,76:100], use="pairwise") 
head(unlist(matrix)[,1:5], 10)
corrplot(corr= matrix4, method = "square")

```

```{r}
#comparing age demographics for white and non-white races

scale_data %>%
filter(race == "White") %>%
summarize(mean(age))

scale_data %>%
filter(race != "White") %>%
summarize(mean(age))

break_down<- scale_data %>%
  group_by(gender, race, country) %>%
  mutate(avg_age= mean(age))

#visualizing demographics

break_down %>%
  ggplot(aes(avg_age, race))+
  geom_col(aes(fill = gender), position = "dodge") +
  facet_wrap(~country, ncol= 2) +
  theme_minimal()
```

```{r}
#visualizing mean responses for each factor 

mean_scores <- scale_data_long %>% 
  group_by(item) %>% 
  summarize(mean = mean(score))

mean_scores %>% 
  mutate(item = parse_number(item)) %>% 
  mutate(factor = case_when(
    item <= 25 ~ "Anxiety",
    item > 25 & item <= 50 ~ "Hopelessness",
    item > 50 & item <= 75 ~ "Resentment",
    item > 75 ~ "Shame")) %>% 
  ggplot(aes(x = item, y = mean)) +
  geom_col(fill= "blue1") +
  labs(y = "Mean Response (1-5)",
       x = "Item",
       title = "Mean Responses to Items by Factor") +
  facet_wrap(~factor) +
  theme_minimal() 
```

## Manuscript Text

Imagination is a fundamental human ability which permeates our daily experiences, influencing everything from the mundane to the grand narratives of myths and legends. Central to creativity, problem-solving, and foresight, imagination shapes our perceptions of reality and the cognitive schemas we use to interpret the world around us (Gotlieb et al., 2019). As a multifaceted construct, imagination involves varying levels of mental imagery, social cognition, mental simulation, emotion, and temporal exploration (Abraham, 2016), using combinations of existing memory to create an experience distinct from external sensory stimuli. Though widely recognized as a positively valanced construct, imagination plays a complex role in mental health and personality. The tendency to frequently and intensely envision negative future scenarios is a feature of clinical depression (Gotlib & Joormann, 2010; Zetsche et al., 2019) and anxiety (Wu et al., 2015), while difficulty in distinguishing imagination from reality plays a role in thought disorders such as schizophrenia (Rasmussen et al., 2022; Jardri & Thomas, 2013). The intersection of imagination with psychopathology, as explored by Kaufman (2014) and Holmes & Mathews (2010), highlights the challenges associated with measuring such a complex construct and evaluating its impacts on mental health.

# The Imaginative Process

Imagination is a cognitive function that encompasses various processes and is integral to human psychological functioning across a range of contexts. Abraham (2016) identifies five core categories that define imagination: perceptual/motor-related mental imagery, intentionality or recollective processing, novel combinatorial or generative processing, aesthetic phenomenology, and altered psychological states. This is extended by Crespi (2020), who asserts there are seven major components of imagination: pretend play, creativity, narratives and aesthetics, mental time travel, salience, mental imagery and sensory systems, and a neural system enabling imagination. These categories, grounded in both philosophical theory and empirical neuroscience evidence, highlight imagination's virtually limitless capacity and varied manifestations. Each category has a distinct neural basis and operates through separate cognitive systems, contributing to the multifaceted nature of imaginative cognition. Common processes, such as mental simulation (Markman et al., 2012), mental time travel (Suddendorf, 1997), and perspective-taking (Batson, 2009), involve dynamic interplay between these categories. This interplay allows individuals to transcend the immediate present with novel thoughts about possible, past, and future scenarios. 

Mullally & Maguire (2014) emphasize that memory forms the foundation for such imaginative projections, enabling the construction of future scenarios based on past experiences. This predictive aspect of imagination (“foresight”) is crucial for adaptive functioning, often aligned with personal and social objectives through cognitive control mechanisms @Sass:01d. While the neuroscientific understanding of some aspects of imagination, such as imagery, is well-developed, others like altered states remain less explored. One key area in this ongoing exploration is the Default Mode Network (DMN; Buckner et al., 2008), which Andrews-Hanna & Grilli (2021) have linked to various imaginative processes. Continual research into the facets of imagination is poised to uncover new insights and relationships, as underscored by the works of Abraham (2016) and Sassenberg et al. (2023). However, it’s crucial to recognize that dysfunction in imagination, such as excessive daydreaming (Somer, 2002) or problematic psychological states (Abraham, 2016) can be maladaptive. This underscores the importance of imagination as both a cognitive function and an enduring source of individual differences across the lifespan.

The evolution in psychometric research towards multifactor, dimensional models reflects a significant shift in how imagination is measured. Historically, tools like the Torrance Tests of Creative Thinking (TCTT; Torrance, 1974) and Gough’s (1979) Creative Personality Scale approached assessing imagination as a component of creativity. However, recent advancements have led to direct measures of imagination as a standalone construct. Notable advancements include the Imaginal Processes Inventory (IPI; Singer & Antrobus, 1963; Singer & Antrobus, 1966), a cross-cultural measure by Feng et al. (2017), and dimensional scales such as the Four-Factor Imagination Scale (FFIS; Zabelina & Condon, 2020) and the Dual-Factor Imagination Scale (DFIS; Sassenberg et al., 2023). The FFIS, in particular, offers a comprehensive evaluation of imagination, assessing the of dimensions Frequency (duration of time spent in imagination), Complexity (elaboration of imaginative activity), Emotional Valence (the emotional content of imagination), and Directedness (the extent to which imagination is goal-oriented). This approach aligns with contemporary frameworks of imagination and is powerful in exploring the range of imagination's features, from its adaptive components to its potential role in adverse psychological outcomes.

With the multi-faceted nature of imagination and its potential intersection with maladaptive traits, it’s important to understand its psychometric structure.

The Current Study

This study aims to explore the factor structure of imagination using a pool of 100 items administered to 10,000 participants.

